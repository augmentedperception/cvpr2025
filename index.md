---
layout: default
---

## Organizers
<p style="text-align: center; font-size: 125%;"> Sean Fanello, Federico Tombari, Thabo Beeler, Andrea Colaco
</p>
<p style="text-align: center; font-size: 125%;"> <b> Google </b> </p>
<p style="text-align:center"><img src="https://www.seanfanello.it/wp-content/uploads/2025/05/cvpr25_tutorial.png"/></p>

## Description
[Google Android XR](https://blog.google/products/android/android-xr/) is a new operating system built for this next generation of computing. At the heart of this platform, Computer Vision and Machine Learning are pivotal in ensuring immersive user experiences. In this tutorial, in particular, we will describe how we built from the ground up the full Perception stack: from head tracking algorithms, all the way to photorealistic avatars and scene renderings. Additionally, researchers and engineers will have access to comprehensive references and documentation of the APIs used in this project.

The tutorial begins by emphasizing the significance of data capture, rendering, and groundtruth generation for Perception tasks such as hand, face, and eye tracking.

Next, we explore the construction of an efficient Perception stack, encompassing egocentric head tracking, hand tracking, face tracking, and eye tracking.

Furthermore, we demonstrate how these perception capabilities enable the creation of scalable and efficient photorealistic representations of humans and scenes.

Finally, we showcase use cases and experiences that leverage the full stack, highlighting its potential applications.


## When and Where
June 12th - 9.00am CDT - Room 201B (Subject to change!), Music City Center, Nashville TN.


## Program

| Time          | Title                                                          | Speaker                                                       |
|:--------------|:---------------------------------------------------------------|:--------------------------------------------------------------|
|               | **Morning: Sensing and Perception on Android XR** |                                                               |
| 9:00-9:15     | Intro: Android XR & Project Moohan                             | Sean Fanello (Google)<br>Sean (Sung Soo) Choi (Samsung)        |
| 9:15-9:30     | Digitization                                                   | Sergio Orts Escolano (Google)<br>Erroll Wood (Google)                     |
| 9:30-10:00    | Foundational Human Models for XR                               | Stefanos Zafeiriou (Google)                                   |
| 10:00-10:15   | Synthetic Data for ML                                          | Erroll Wood (Google)                                          |
| 10:15-10:30   | Background for OpenPX and Perception hosting service           | Jinshik Bae (Samsung)                                         |
| 10:30-10:45   | Real-world scenario of OpenPX - Fit guide in XR                | Donghwan Seo (Samsung)                                        |
| 10:45-11:00   | <span style="color: mediumvioletred;">*Coffee Break*</span> |                                                               |
| 11:00-11:20   | World Tracking for XR                                          | Abhijeet Bisain (Qualcomm)                                    |
| 11:20-11:45   | Hand Tracking for XR                                           | Jonathan Taylor (Google)<br>Abhijeet Bisain (Qualcomm)         |
| 11:45-12:10   | Face Tracking for XR                                           | Sergio Orts Escolano (Google)                                 |
| 12:10-12:35   | Body Tracking for XR                                           | Alexandru-Eugen Ichim (Google)                                |
| 12:35-13:00   | Eye Tracking for XR                                            | Ivana Tosic Rodgers (Google)                                  |
| 13:00-14:00   | <span style="color: mediumvioletred;">*Lunch Break*</span> |                                                               |
|               | **Afternoon: Interaction and Rendering on Android XR** |                                                               |
| 14:00-14:30   | Video See Through                                              | Eric Turner (Google)<br>Abhijeet Bisain (Qualcomm)             |
| 14:30-15:00   | Novel View Synthesis for XR                                    | Fabian Manhardt (Google)                                      |
| 15:00-15:30   | Open Set 3D Scene Understanding for XR                         | Federico Tombari (Google)                                     |
| 15:30-15:50   | 3D Assets and Immersive Scene Generation for XR                | Michael Oechsle (Google)                                      |
| 15:50-16:00   | <span style="color: mediumvioletred;">*Coffee Break*</span> |                                                               |
| 16:00-16:30   | Scalable Photorealistic Avatars                                | Yinda Zhang (Google)<br>Yan Deng (Qualcomm)                    |
| 16:30-17:00   | Interaction Framework for XR                                   | Andrea Colaco (Google)                                        |
| 17:00-17:30   | Interactive Perception & Graphics for a Universally Accessible XR | Ruofei Du (Google)                                            |


Please contact [Sean Fanello](mailto:seanfa@google.com) if you have any questions.
