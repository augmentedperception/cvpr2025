## Organizers
<p style="text-align: center;"> Sean Fanello, Federico Tombari, Thabo Beeler, Andrea Colaco
</p>
<p style="text-align: center;"> <b> Google </b> </p>
<p style="text-align:center"><img src="https://www.seanfanello.it/wp-content/uploads/2025/05/cvpr25_tutorial.png"/></p>

## Description
[Google Android XR](https://blog.google/products/android/android-xr/) is a new operating system built for this next generation of computing. At the heart of this platform, Computer Vision and Machine Learning are pivotal in ensuring immersive user experiences. In this tutorial, in particular, we will describe how we built from the ground up the full Perception stack: from head tracking algorithms, all the way to photorealistic avatars and scene renderings. Additionally, researchers and engineers will have access to comprehensive references and documentation of the APIs used in this project.

The tutorial begins by emphasizing the significance of data capture, rendering, and groundtruth generation for Perception tasks such as hand, face, and eye tracking.

Next, we explore the construction of an efficient Perception stack, encompassing egocentric head tracking, hand tracking, face tracking, and eye tracking.

Furthermore, we demonstrate how these perception capabilities enable the creation of scalable and efficient photorealistic representations of humans and scenes.

Finally, we showcase use cases and experiences that leverage the full stack, highlighting its potential applications.


## When and Where
June 12th - 9.00 am CDT - Room TBD , Music City Center, Nashville TN.


## Program
Coming soon
</table>

Please contact [Sean Fanello](mailto:seanfa@google.com) if you have any questions.
